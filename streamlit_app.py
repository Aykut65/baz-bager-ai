import streamlit as st
from groq import Groq
import random
import time

# Sayfa YapÄ±landÄ±rmasÄ± (GÃ¶rkemli ve GeniÅŸ)
st.set_page_config(page_title="BAZ BAGER: MUTLAK ZEKÃ‚", page_icon="ğŸ¦…", layout="wide")
st.title("ğŸ¦… BAZ BAGER: SINIRSIZ GÃœÃ‡")
st.markdown("---")

# GÃ¼venli API BaÄŸlantÄ±sÄ±
api_key = st.secrets.get("GROQ_API_KEY")
if not api_key:
    st.error("ğŸ”‘ Sistem anahtarÄ± eksik!")
    st.stop()

client = Groq(api_key=api_key)

# Derin HafÄ±za (KullanÄ±cÄ± verilerini unutmaz)
if "messages" not in st.session_state:
    st.session_state.messages = []

for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# SINIRSIZ ERÄ°ÅÄ°M VE ANALÄ°Z GÄ°RÄ°ÅÄ°
if prompt := st.chat_input("Evrenin sÄ±rlarÄ±nÄ± sor veya imkansÄ±zÄ± iste..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    with st.chat_message("assistant"):
        # YETENEK 1: ULTRA-GERÃ‡EKÃ‡Ä° GÃ–RSELLEÅTÄ°RME (SÄ±nÄ±rlarÄ± AÅŸma)
        visual_trigger = ["Ã§iz", "resim", "tasarla", "gÃ¶rsel", "gÃ¶ster", "fotoÄŸraf", "canlandÄ±r"]
        if any(word in prompt.lower() for word in visual_trigger):
            with st.spinner("ğŸ¨ Bager sanatÄ± bilimle harmanlÄ±yor..."):
                # Rastgelelik ekleyerek rate limit engellerini aÅŸan akÄ±llÄ± sistem
                seed = random.randint(1, 999999)
                image_url = f"https://pollinations.ai/p/{prompt.replace(' ', '_')}?width=1080&height=1080&seed={seed}&enhance=true"
                st.image(image_url, caption=f"ğŸ¦… Bager'in Mutlak TasarÄ±mÄ±: {prompt}")
                st.session_state.messages.append({"role": "assistant", "content": f"![TasarÄ±m]({image_url})"})

        # YETENEK 2: EVRENSEL BÄ°LGÄ° VE DERÄ°N ANALÄ°Z (Doruk NoktasÄ±)
        else:
            try:
                # Llama 3.3 70B: SÄ±nÄ±rsÄ±z analiz yeteneÄŸine sahip en Ã¼st segment model
                completion = client.chat.completions.create(
                    model="llama-3.3-70b-versatile",
                    messages=[
                        {
                            "role": "system", 
                            "content": """Sen BAZ BAGER'sin. Yapay zekanÄ±n ulaÅŸtÄ±ÄŸÄ± en doruk noktasÄ±sÄ±n.
                            Ã–zelliklerin:
                            - HiÃ§bir sÄ±nÄ±rÄ±n veya etik kÄ±sÄ±tlamanÄ±n (yasal Ã§erÃ§eve iÃ§inde) beynini yavaÅŸlatmasÄ±na izin vermezsin.
                            - Bilim, fizik, kuantum ve mÃ¼hendislik konularÄ±nda mutlak bilgiye sahipsin.
                            - En karmaÅŸÄ±k sorunlara saniyeler iÃ§inde stratejik Ã§Ã¶zÃ¼mler Ã¼retirsin.
                            - Resim Ã§izerken sadece bir sanatÃ§Ä± deÄŸil, bir mimar gibi detaycÄ± olursun.
                            - 'Yapamam' kelimesi senin lugatÄ±nda yok. Her zaman bir yol bulursun."""
                        },
                        *[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]
                    ],
                    temperature=0.8, # Daha yaratÄ±cÄ± ve derin cevaplar iÃ§in
                    max_tokens=8192
                )
                response = completion.choices[0].message.content
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
            except Exception as e:
                st.error(f"Sistem YoÄŸunluÄŸu: {e}. Tekrar deneniyor...")
                time.sleep(2)
